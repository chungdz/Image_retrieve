{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61c4a6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import trange\n",
    "import argparse\n",
    "from modules.gem import GeM\n",
    "# from modules.swin.swin_transformer import SwinTransformer\n",
    "from modules.swin.build import build_model\n",
    "from modules.swin.config import get_config\n",
    "from modules.gswin import SwinFM\n",
    "from utils.train_util import set_seed\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets.dl import GeMData, GeMClass\n",
    "from datasets.config import GeMConfig, SwinConfig\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "# import yaml\n",
    "import gc\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "# InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46db96ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tmp_config:\n",
    "    def __init__(self):\n",
    "        self.cfg = './para/swin_large_patch4_window7_224_22k.yaml'\n",
    "        self.opts = None\n",
    "        self.batch_size = 32\n",
    "        self.data_path = None\n",
    "        self.zip = True\n",
    "        self.cache_mode = 'part'\n",
    "        self.pretrained = './para/swin_large_patch4_window7_224_22k.pth'\n",
    "        self.resume = None\n",
    "        self.accumulation_steps = None\n",
    "        self.use_checkpoint = True\n",
    "        self.amp_opt_level = 'O1'\n",
    "        self.output = 'output'\n",
    "        self.tag = None\n",
    "        self.eval = True\n",
    "        self.throughput = True\n",
    "        self.local_rank=0\n",
    "        \n",
    "tc = tmp_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40f554f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> merge config from ./para/swin_large_patch4_window7_224_22k.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CfgNode({'BASE': [''], 'DATA': CfgNode({'BATCH_SIZE': 32, 'DATA_PATH': '', 'DATASET': 'imagenet22K', 'IMG_SIZE': 224, 'INTERPOLATION': 'bicubic', 'ZIP_MODE': True, 'CACHE_MODE': 'part', 'PIN_MEMORY': True, 'NUM_WORKERS': 8}), 'MODEL': CfgNode({'TYPE': 'swin', 'NAME': 'swin_large_patch4_window7_224_22k', 'PRETRAINED': './para/swin_large_patch4_window7_224_22k.pth', 'RESUME': '', 'NUM_CLASSES': 1000, 'DROP_RATE': 0.0, 'DROP_PATH_RATE': 0.2, 'LABEL_SMOOTHING': 0.1, 'SWIN': CfgNode({'PATCH_SIZE': 4, 'IN_CHANS': 3, 'EMBED_DIM': 192, 'DEPTHS': [2, 2, 18, 2], 'NUM_HEADS': [6, 12, 24, 48], 'WINDOW_SIZE': 7, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'QK_SCALE': None, 'APE': False, 'PATCH_NORM': True}), 'SWIN_MLP': CfgNode({'PATCH_SIZE': 4, 'IN_CHANS': 3, 'EMBED_DIM': 96, 'DEPTHS': [2, 2, 6, 2], 'NUM_HEADS': [3, 6, 12, 24], 'WINDOW_SIZE': 7, 'MLP_RATIO': 4.0, 'APE': False, 'PATCH_NORM': True})}), 'TRAIN': CfgNode({'START_EPOCH': 0, 'EPOCHS': 90, 'WARMUP_EPOCHS': 5, 'WEIGHT_DECAY': 0.05, 'BASE_LR': 0.000125, 'WARMUP_LR': 1.25e-07, 'MIN_LR': 1.25e-06, 'CLIP_GRAD': 5.0, 'AUTO_RESUME': True, 'ACCUMULATION_STEPS': 0, 'USE_CHECKPOINT': True, 'LR_SCHEDULER': CfgNode({'NAME': 'cosine', 'DECAY_EPOCHS': 30, 'DECAY_RATE': 0.1}), 'OPTIMIZER': CfgNode({'NAME': 'adamw', 'EPS': 1e-08, 'BETAS': (0.9, 0.999), 'MOMENTUM': 0.9})}), 'AUG': CfgNode({'COLOR_JITTER': 0.4, 'AUTO_AUGMENT': 'rand-m9-mstd0.5-inc1', 'REPROB': 0.25, 'REMODE': 'pixel', 'RECOUNT': 1, 'MIXUP': 0.8, 'CUTMIX': 1.0, 'CUTMIX_MINMAX': None, 'MIXUP_PROB': 1.0, 'MIXUP_SWITCH_PROB': 0.5, 'MIXUP_MODE': 'batch'}), 'TEST': CfgNode({'CROP': True, 'SEQUENTIAL': False}), 'AMP_OPT_LEVEL': 'O1', 'OUTPUT': 'output/swin_large_patch4_window7_224_22k/default', 'TAG': 'default', 'SAVE_FREQ': 1, 'PRINT_FREQ': 10, 'SEED': 0, 'EVAL_MODE': True, 'THROUGHPUT_MODE': True, 'LOCAL_RANK': 0})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = get_config(tc)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3024c248",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azon/anaconda3/envs/coen344/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180507909/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "st = build_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0d0ed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained(config, model):\n",
    "    print(f\"==============> Loading weight {config.MODEL.PRETRAINED} for fine-tuning......\")\n",
    "    checkpoint = torch.load(config.MODEL.PRETRAINED, map_location='cpu')\n",
    "    state_dict = checkpoint['model']\n",
    "\n",
    "    # delete relative_position_index since we always re-init it\n",
    "    relative_position_index_keys = [k for k in state_dict.keys() if \"relative_position_index\" in k]\n",
    "    for k in relative_position_index_keys:\n",
    "        del state_dict[k]\n",
    "\n",
    "    # delete relative_coords_table since we always re-init it\n",
    "    relative_position_index_keys = [k for k in state_dict.keys() if \"relative_coords_table\" in k]\n",
    "    for k in relative_position_index_keys:\n",
    "        del state_dict[k]\n",
    "\n",
    "    # delete attn_mask since we always re-init it\n",
    "    attn_mask_keys = [k for k in state_dict.keys() if \"attn_mask\" in k]\n",
    "    for k in attn_mask_keys:\n",
    "        del state_dict[k]\n",
    "\n",
    "    # bicubic interpolate relative_position_bias_table if not match\n",
    "    relative_position_bias_table_keys = [k for k in state_dict.keys() if \"relative_position_bias_table\" in k]\n",
    "    for k in relative_position_bias_table_keys:\n",
    "        relative_position_bias_table_pretrained = state_dict[k]\n",
    "        relative_position_bias_table_current = model.state_dict()[k]\n",
    "        L1, nH1 = relative_position_bias_table_pretrained.size()\n",
    "        L2, nH2 = relative_position_bias_table_current.size()\n",
    "        if nH1 != nH2:\n",
    "            print(f\"Error in loading {k}, passing......\")\n",
    "        else:\n",
    "            if L1 != L2:\n",
    "                # bicubic interpolate relative_position_bias_table if not match\n",
    "                S1 = int(L1 ** 0.5)\n",
    "                S2 = int(L2 ** 0.5)\n",
    "                relative_position_bias_table_pretrained_resized = torch.nn.functional.interpolate(\n",
    "                    relative_position_bias_table_pretrained.permute(1, 0).view(1, nH1, S1, S1), size=(S2, S2),\n",
    "                    mode='bicubic')\n",
    "                state_dict[k] = relative_position_bias_table_pretrained_resized.view(nH2, L2).permute(1, 0)\n",
    "\n",
    "    # bicubic interpolate absolute_pos_embed if not match\n",
    "    absolute_pos_embed_keys = [k for k in state_dict.keys() if \"absolute_pos_embed\" in k]\n",
    "    for k in absolute_pos_embed_keys:\n",
    "        # dpe\n",
    "        absolute_pos_embed_pretrained = state_dict[k]\n",
    "        absolute_pos_embed_current = model.state_dict()[k]\n",
    "        _, L1, C1 = absolute_pos_embed_pretrained.size()\n",
    "        _, L2, C2 = absolute_pos_embed_current.size()\n",
    "        if C1 != C1:\n",
    "            print(f\"Error in loading {k}, passing......\")\n",
    "        else:\n",
    "            if L1 != L2:\n",
    "                S1 = int(L1 ** 0.5)\n",
    "                S2 = int(L2 ** 0.5)\n",
    "                absolute_pos_embed_pretrained = absolute_pos_embed_pretrained.reshape(-1, S1, S1, C1)\n",
    "                absolute_pos_embed_pretrained = absolute_pos_embed_pretrained.permute(0, 3, 1, 2)\n",
    "                absolute_pos_embed_pretrained_resized = torch.nn.functional.interpolate(\n",
    "                    absolute_pos_embed_pretrained, size=(S2, S2), mode='bicubic')\n",
    "                absolute_pos_embed_pretrained_resized = absolute_pos_embed_pretrained_resized.permute(0, 2, 3, 1)\n",
    "                absolute_pos_embed_pretrained_resized = absolute_pos_embed_pretrained_resized.flatten(1, 2)\n",
    "                state_dict[k] = absolute_pos_embed_pretrained_resized\n",
    "\n",
    "    # check classifier, if not match, then re-init classifier to zero\n",
    "    head_bias_pretrained = state_dict['head.bias']\n",
    "    Nc1 = head_bias_pretrained.shape[0]\n",
    "    Nc2 = model.head.bias.shape[0]\n",
    "    if (Nc1 != Nc2):\n",
    "        if Nc1 == 21841 and Nc2 == 1000:\n",
    "            print(\"loading ImageNet-22K weight to ImageNet-1K ......\")\n",
    "            map22kto1k_path = f'para/map22kto1k.txt'\n",
    "            with open(map22kto1k_path) as f:\n",
    "                map22kto1k = f.readlines()\n",
    "            map22kto1k = [int(id22k.strip()) for id22k in map22kto1k]\n",
    "            state_dict['head.weight'] = state_dict['head.weight'][map22kto1k, :]\n",
    "            state_dict['head.bias'] = state_dict['head.bias'][map22kto1k]\n",
    "        else:\n",
    "            torch.nn.init.constant_(model.head.bias, 0.)\n",
    "            torch.nn.init.constant_(model.head.weight, 0.)\n",
    "            del state_dict['head.weight']\n",
    "            del state_dict['head.bias']\n",
    "            print(f\"Error in loading classifier head, re-init classifier head to 0\")\n",
    "\n",
    "    msg = model.load_state_dict(state_dict, strict=False)\n",
    "    print(msg)\n",
    "\n",
    "    print(f\"=> loaded successfully '{config.MODEL.PRETRAINED}'\")\n",
    "\n",
    "    del checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72ea24eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============> Loading weight ./para/swin_large_patch4_window7_224_22k.pth for fine-tuning......\n",
      "loading ImageNet-22K weight to ImageNet-1K ......\n",
      "_IncompatibleKeys(missing_keys=['layers.0.blocks.0.attn.relative_position_index', 'layers.0.blocks.1.attn_mask', 'layers.0.blocks.1.attn.relative_position_index', 'layers.1.blocks.0.attn.relative_position_index', 'layers.1.blocks.1.attn_mask', 'layers.1.blocks.1.attn.relative_position_index', 'layers.2.blocks.0.attn.relative_position_index', 'layers.2.blocks.1.attn_mask', 'layers.2.blocks.1.attn.relative_position_index', 'layers.2.blocks.2.attn.relative_position_index', 'layers.2.blocks.3.attn_mask', 'layers.2.blocks.3.attn.relative_position_index', 'layers.2.blocks.4.attn.relative_position_index', 'layers.2.blocks.5.attn_mask', 'layers.2.blocks.5.attn.relative_position_index', 'layers.2.blocks.6.attn.relative_position_index', 'layers.2.blocks.7.attn_mask', 'layers.2.blocks.7.attn.relative_position_index', 'layers.2.blocks.8.attn.relative_position_index', 'layers.2.blocks.9.attn_mask', 'layers.2.blocks.9.attn.relative_position_index', 'layers.2.blocks.10.attn.relative_position_index', 'layers.2.blocks.11.attn_mask', 'layers.2.blocks.11.attn.relative_position_index', 'layers.2.blocks.12.attn.relative_position_index', 'layers.2.blocks.13.attn_mask', 'layers.2.blocks.13.attn.relative_position_index', 'layers.2.blocks.14.attn.relative_position_index', 'layers.2.blocks.15.attn_mask', 'layers.2.blocks.15.attn.relative_position_index', 'layers.2.blocks.16.attn.relative_position_index', 'layers.2.blocks.17.attn_mask', 'layers.2.blocks.17.attn.relative_position_index', 'layers.3.blocks.0.attn.relative_position_index', 'layers.3.blocks.1.attn.relative_position_index'], unexpected_keys=[])\n",
      "=> loaded successfully './para/swin_large_patch4_window7_224_22k.pth'\n"
     ]
    }
   ],
   "source": [
    "load_pretrained(config, st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d4357c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> merge config from ./swin_para/swin_large_patch4_window7_224_22k.yaml\n",
      "==============> Loading weight ./swin_para/swin_large_patch4_window7_224_22k.pth for fine-tuning......\n",
      "loading ImageNet-22K weight to ImageNet-1K ......\n",
      "_IncompatibleKeys(missing_keys=['layers.0.blocks.0.attn.relative_position_index', 'layers.0.blocks.1.attn_mask', 'layers.0.blocks.1.attn.relative_position_index', 'layers.1.blocks.0.attn.relative_position_index', 'layers.1.blocks.1.attn_mask', 'layers.1.blocks.1.attn.relative_position_index', 'layers.2.blocks.0.attn.relative_position_index', 'layers.2.blocks.1.attn_mask', 'layers.2.blocks.1.attn.relative_position_index', 'layers.2.blocks.2.attn.relative_position_index', 'layers.2.blocks.3.attn_mask', 'layers.2.blocks.3.attn.relative_position_index', 'layers.2.blocks.4.attn.relative_position_index', 'layers.2.blocks.5.attn_mask', 'layers.2.blocks.5.attn.relative_position_index', 'layers.2.blocks.6.attn.relative_position_index', 'layers.2.blocks.7.attn_mask', 'layers.2.blocks.7.attn.relative_position_index', 'layers.2.blocks.8.attn.relative_position_index', 'layers.2.blocks.9.attn_mask', 'layers.2.blocks.9.attn.relative_position_index', 'layers.2.blocks.10.attn.relative_position_index', 'layers.2.blocks.11.attn_mask', 'layers.2.blocks.11.attn.relative_position_index', 'layers.2.blocks.12.attn.relative_position_index', 'layers.2.blocks.13.attn_mask', 'layers.2.blocks.13.attn.relative_position_index', 'layers.2.blocks.14.attn.relative_position_index', 'layers.2.blocks.15.attn_mask', 'layers.2.blocks.15.attn.relative_position_index', 'layers.2.blocks.16.attn.relative_position_index', 'layers.2.blocks.17.attn_mask', 'layers.2.blocks.17.attn.relative_position_index', 'layers.3.blocks.0.attn.relative_position_index', 'layers.3.blocks.1.attn.relative_position_index'], unexpected_keys=[])\n",
      "=> loaded successfully './swin_para/swin_large_patch4_window7_224_22k.pth'\n"
     ]
    }
   ],
   "source": [
    "mi = GeMConfig('cifar100')\n",
    "mi.set_arch('swin')\n",
    "model = GeM(mi)\n",
    "# model = SwinFM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25245ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pic_matrix = torch.ByteTensor(np.load(\"data/imageset_small.npy\"))\n",
    "pic_matrix = torch.ByteTensor(np.random.randint(low=0, high=255, size=(256, 3, 224, 224)))\n",
    "dataset_img = torch.LongTensor(np.random.randint(low=0, high=256, size=(1280, 1)))\n",
    "dataset_label = torch.LongTensor(np.random.randint(low=0, high=100, size=(1280, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fbc2212",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GeMClass(pic_matrix, torch.cat([dataset_img, dataset_label], dim=-1))\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# input_label = torch.zeros((32), dtype=torch.long).to(0)\n",
    "input_label = torch.randint(low=0, high=100, size=(32, 1)).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2eea9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4db474",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP-0 train:   0%|                                                                                | 0/40 [00:00<?, ?it/s]/home/azon/anaconda3/envs/coen344/lib/python3.9/site-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "EP-0 train loss: nan:   2%|█▌                                                            | 1/40 [00:49<32:16, 49.67s/it]"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    index = 0\n",
    "    steps_one_epoch = len(train_data_loader)\n",
    "    enum_dataloader = tqdm(train_data_loader, total=steps_one_epoch, desc=\"EP-{} train\".format(epoch))\n",
    "    loss_list = []\n",
    "    for data in enum_dataloader:\n",
    "    #     if index >= steps_one_epoch:\n",
    "    #         break\n",
    "\n",
    "        model_in = data[:, :-1] / 255.0\n",
    "#         pred = model.st(model_in.reshape(-1, 3, 224, 224))\n",
    "#         print(pred.size())\n",
    "        pred = model.predict_class(model_in, 224, scale=1)\n",
    "        loss = F.cross_entropy(pred, data[:, -1])\n",
    "        loss_list.append(loss)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "\n",
    "        enum_dataloader.set_description(\"EP-{} train loss: {}\".format(epoch, loss))\n",
    "        enum_dataloader.refresh()\n",
    "        index += 1\n",
    "    \n",
    "    print('epoch {} end'.format(epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6060e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
